{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Directories and categories first print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "\n",
    "TRAIN_DATADIR = \"/home/reinaldo/Documentos/PetImages/database/\"\n",
    "TEST_DATADIR = \"/home/reinaldo/Documentos/PetImages/ALLDATA/\"\n",
    "\n",
    "TRAIN_DATADIR2 = \"/home/reinaldo/Documentos/PetImages2/database/\"\n",
    "TEST_DATADIR2 = \"/home/reinaldo/Documentos/PetImages2/ALLDATA/\"\n",
    "TRAIN_DATADIR3 = \"/home/reinaldo/Documentos/PetImages3/database/\"\n",
    "TEST_DATADIR3 = \"/home/reinaldo/Documentos/PetImages3/ALLDATA/\"\n",
    "\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "img_array = []\n",
    "\n",
    "\n",
    "for category in CATEGORIES:  # do dogs and cats\n",
    "    path = os.path.join(TRAIN_DATADIR,category)  # create path to dogs and cats\n",
    "    for img in os.listdir(path):  # iterate over each image per dogs and cats\n",
    "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "        print(img_array)\n",
    "        plt.imshow(img_array, cmap='gray')  # graph it\n",
    "        plt.show()  # display!\n",
    "\n",
    "        break  # we just want one for now so break\n",
    "    break  #...and one more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 100\n",
    "\n",
    "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "new_array2 = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "plt.imshow(new_array, cmap='gray')\n",
    "plt.imshow(new_array2, cmap='gray')\n",
    "plt.show()\n",
    "print(new_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "test_data = []\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # do dogs and cats\n",
    "\n",
    "        path_train = os.path.join(TRAIN_DATADIR,category)  # create path to dogs and cats to train\n",
    "        path_test = TEST_DATADIR  # create path to dogs and cats to test\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in tqdm(os.listdir(path_train)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path_train,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num, int(img.split('.')[0])])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "    for img in tqdm(os.listdir(path_test)):  # iterate over each image per dogs and cats\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(path_test,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "            new_array2 = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "            test_data.append([new_array2, class_num,int(img.split('.')[0])])  # add this to our training_data\n",
    "        except Exception as e:  # in the interest in keeping the output clean...\n",
    "            pass            \n",
    "           \n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))\n",
    "print(len(test_data))\n",
    "print(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)\n",
    "random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "X_train = []\n",
    "y_test = []\n",
    "y_train = []\n",
    "z_train = []\n",
    "z_test = []\n",
    "\n",
    "for features,label,file_name in training_data:\n",
    "    X_train.append(features)\n",
    "    y_train.append(label)\n",
    "    z_train.append(file_name)\n",
    "\n",
    "print(X_train[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "for features,label,file_name in test_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)\n",
    "    z_test.append(file_name)\n",
    "\n",
    "#print(X_test[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X_test.pickle\",\"wb\")\n",
    "pickle.dump(X_test,pickle_out)\n",
    "\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_test.pickle\",\"wb\")\n",
    "pickle.dump(y_test, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"X_train.pickle\",\"wb\")\n",
    "pickle.dump(X_train,pickle_out)\n",
    "\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_train.pickle\",\"wb\")\n",
    "pickle.dump(y_train, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data on pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can always load it in to our current script, or a totally new one by doing:\n",
    "\n",
    "pickle_in = open(\"X_train.pickle\",\"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_train.pickle\",\"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "pickle_in = open(\"X_test.pickle\",\"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_test.pickle\",\"rb\")\n",
    "y_test = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply data on first training machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_in = open(\"X_train.pickle\",\"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_train.pickle\",\"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"X_test.pickle\",\"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_test.pickle\",\"rb\")\n",
    "y_test = pickle.load(pickle_in)\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test,2)\n",
    "y_train = np_utils.to_categorical(y_train,2)\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(20, (3, 3), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(20, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(20))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=20, epochs=5, validation_split=0.1)\n",
    "\n",
    "print(\"Calculating prediction\")\n",
    "prediction = model.predict(X_test, batch_size=20)\n",
    "print(prediction)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:]))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model2.add(Dense(64))\n",
    "\n",
    "model2.add(Dense(2))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n",
    "model2.fit(X_train, y_train, batch_size=32, epochs=5, validation_split=0.1)\n",
    "\n",
    "print(\"Calculating prediction\")\n",
    "prediction2 = model2.predict(X_test, batch_size=32)\n",
    "print(prediction2)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv2D(16, (3, 3), input_shape=X_train.shape[1:]))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Conv2D(16, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model3.add(Dense(10))\n",
    "\n",
    "model3.add(Dense(2))\n",
    "model3.add(Activation('softmax'))\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n",
    "model3.fit(X_train, y_train, batch_size=32, epochs=5, validation_split=0.3)\n",
    "\n",
    "print(\"Calculating prediction\")\n",
    "prediction3 = model3.predict(X_test, batch_size=16)\n",
    "print(prediction3)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sorting the predictions without lose index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = np.insert(prediction, 2, z_test , axis =1)\n",
    "label_pred2 = np.insert(prediction2, 2, z_test , axis =1)\n",
    "label_pred3 = np.insert(prediction3, 2, z_test , axis =1)\n",
    "print(label_pred)\n",
    "print(label_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_sorte = np.sort(label_pred, axis = 0)[::-1]\n",
    "cat_sort = label_pred[label_pred[:,0].argsort()]\n",
    "dog_sort = label_pred[label_pred[:,1].argsort()]\n",
    "\n",
    "cat_sort2 = label_pred2[label_pred2[:,0].argsort()]\n",
    "dog_sort2 = label_pred2[label_pred2[:,1].argsort()]\n",
    "\n",
    "cat_sort3 = label_pred3[label_pred3[:,0].argsort()]\n",
    "dog_sort3 = label_pred3[label_pred3[:,1].argsort()]\n",
    "print(cat_sort[::-1])\n",
    "print(dog_sort[::-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#odenar e escolher 100 melhores de cada categoria mo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving images to paths of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil as st\n",
    "\n",
    "ja_treinado =\"/home/reinaldo/Documentos/PetImages/ja_treinado\" \n",
    "ja_treinado2 =\"/home/reinaldo/Documentos/PetImages2/ja_treinado\" \n",
    "ja_treinado3 =\"/home/reinaldo/Documentos/PetImages3/ja_treinado\" \n",
    "for img in os.listdir(TRAIN_DATADIR+\"/Cat/\"):\n",
    "    st.move(TRAIN_DATADIR+\"/Cat/\"+img,ja_treinado+\"/Cat/\"+img)\n",
    "for img in os.listdir(TRAIN_DATADIR+\"/Dog/\"):\n",
    "    st.move(TRAIN_DATADIR+\"/Dog/\"+img,ja_treinado+\"/Dog/\"+img)\n",
    "    \n",
    "for img in os.listdir(TRAIN_DATADIR2+\"/Cat/\"):\n",
    "    st.move(TRAIN_DATADIR2+\"/Cat/\"+img,ja_treinado+\"/Cat/\"+img)\n",
    "for img in os.listdir(TRAIN_DATADIR2+\"/Dog/\"):\n",
    "    st.move(TRAIN_DATADIR2+\"/Dog/\"+img,ja_treinado+\"/Dog/\"+img)\n",
    "    \n",
    "for img in os.listdir(TRAIN_DATADIR3+\"/Cat/\"):\n",
    "    st.move(TRAIN_DATADIR3+\"/Cat/\"+img,ja_treinado+\"/Cat/\"+img)\n",
    "for img in os.listdir(TRAIN_DATADIR3+\"/Dog/\"):\n",
    "    st.move(TRAIN_DATADIR3+\"/Dog/\"+img,ja_treinado+\"/Dog/\"+img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving better test images from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    #path of test to training cats\n",
    "    st.move(TEST_DATADIR+str(int(cat_sort[i][2]))+\".jpg\",TRAIN_DATADIR+\"Cat/\"+str(int(cat_sort[i][2]))+\".jpg\")\n",
    "    #path of test to training dogs\n",
    "    st.move(TEST_DATADIR+str(int(dog_sort[i][2]))+\".jpg\",TRAIN_DATADIR+\"Dog/\"+str(int(dog_sort[i][2]))+\".jpg\")\n",
    "for i in range(100):\n",
    "    #path of test to training cats\n",
    "    st.move(TEST_DATADIR2+str(int(cat_sort2[i][2]))+\".jpg\",TRAIN_DATADIR2+\"Cat/\"+str(int(cat_sort2[i][2]))+\".jpg\")\n",
    "    #path of test to training dogs\n",
    "    st.move(TEST_DATADIR2+str(int(dog_sort2[i][2]))+\".jpg\",TRAIN_DATADIR2+\"Dog/\"+str(int(dog_sort2[i][2]))+\".jpg\")\n",
    "for i in range(100):\n",
    "    #path of test to training cats\n",
    "    st.move(TEST_DATADIR3+str(int(cat_sort3[i][2]))+\".jpg\",TRAIN_DATADIR3+\"Cat/\"+str(int(cat_sort3[i][2]))+\".jpg\")\n",
    "    #path of test to training dogs\n",
    "    st.move(TEST_DATADIR3+str(int(dog_sort3[i][2]))+\".jpg\",TRAIN_DATADIR3+\"Dog/\"+str(int(dog_sort3[i][2]))+\".jpg\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New training on the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ite=0\n",
    "while os.listdir(TEST_DATADIR) and ite<5:\n",
    "    ite=ite+1\n",
    "    training_data = []\n",
    "    test_data = []\n",
    "    create_training_data()\n",
    "    print(\"tamanho de training data\")\n",
    "    print(len(training_data))\n",
    "    print(\"tamanho de test data\")\n",
    "    print(len(test_data))\n",
    "    random.shuffle(training_data)\n",
    "    random.shuffle(test_data)\n",
    "\n",
    "    X_test = []\n",
    "    X_train = []\n",
    "    y_test = []\n",
    "    y_train = []\n",
    "    z_train = []\n",
    "    z_test = []\n",
    "\n",
    "    for features,label,file_name in training_data:\n",
    "        X_train.append(features)\n",
    "        y_train.append(label)\n",
    "        z_train.append(file_name)\n",
    "\n",
    "    X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "    for features,label,file_name in test_data:\n",
    "        X_test.append(features)\n",
    "        y_test.append(label)\n",
    "        z_test.append(file_name)\n",
    "\n",
    "    X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    y_test = np_utils.to_categorical(y_test,2)\n",
    "    y_train = np_utils.to_categorical(y_train,2)\n",
    "\n",
    "    X_train = X_train/255.0\n",
    "    X_test = X_test/255.0\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=5, validation_split=0.3)\n",
    "    print(\"Calculating prediction\")\n",
    "    prediction = model.predict(X_test, batch_size=1)\n",
    "    print(\"done\")\n",
    "    pred_index = np.argsort(prediction)\n",
    "\n",
    "    label_pred = np.insert(prediction, 2, z_test , axis =1)\n",
    "\n",
    "    print(label_pred)\n",
    "    print(label_pred.shape)\n",
    "\n",
    "    cat_sort = label_pred[label_pred[:,0].argsort()]\n",
    "    dog_sort = label_pred[label_pred[:,1].argsort()]\n",
    "    \n",
    "\n",
    "    ja_treinado =\"/home/reinaldo/Documentos/PetImages/ja_treinado\" \n",
    "    for img in os.listdir(TRAIN_DATADIR+\"/Cat/\"):\n",
    "        st.move(TRAIN_DATADIR+\"/Cat/\"+img,ja_treinado+\"/Cat/\"+img)\n",
    "    for img in os.listdir(TRAIN_DATADIR+\"/Dog/\"):\n",
    "        st.move(TRAIN_DATADIR+\"/Dog/\"+img,ja_treinado+\"/Dog/\"+img)\n",
    "    if len(os.listdir(TEST_DATADIR))>100:\n",
    "        for i in range(100):\n",
    "            #path of test to training cats\n",
    "            try:\n",
    "                st.move(TEST_DATADIR+str(int(cat_sort[i][2]))+\".jpg\",TRAIN_DATADIR+\"Cat/\"+str(int(cat_sort[i][2]))+\".jpg\")\n",
    "            #path of test to training dogs\n",
    "                st.move(TEST_DATADIR+str(int(dog_sort[i][2]))+\".jpg\",TRAIN_DATADIR+\"Dog/\"+str(int(dog_sort[i][2]))+\".jpg\")\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        \n",
    "        for i in range(len(os.listdir(TEST_DATADIR))):\n",
    "            #path of test to training cats\n",
    "            try:\n",
    "                st.move(TEST_DATADIR+str(int(cat_sort[i][2]))+\".jpg\",TRAIN_DATADIR+\"Cat/\"+str(int(cat_sort[i][2]))+\".jpg\")\n",
    "            #path of test to training dogs\n",
    "                st.move(TEST_DATADIR+str(int(dog_sort[i][2]))+\".jpg\",TRAIN_DATADIR+\"Dog/\"+str(int(dog_sort[i][2]))+\".jpg\")\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop backpropagation for Second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ite=0\n",
    "while os.listdir(TEST_DATADIR2) and ite<5:\n",
    "    ite=ite+1\n",
    "    training_data = []\n",
    "    test_data = []\n",
    "    create_training_data()\n",
    "    print(\"tamanho de training data\")\n",
    "    print(len(training_data))\n",
    "    print(\"tamanho de test data\")\n",
    "    print(len(test_data))\n",
    "    random.shuffle(training_data)\n",
    "    random.shuffle(test_data)\n",
    "\n",
    "    X_test = []\n",
    "    X_train = []\n",
    "    y_test = []\n",
    "    y_train = []\n",
    "    z_train = []\n",
    "    z_test = []\n",
    "\n",
    "    for features,label,file_name in training_data:\n",
    "        X_train.append(features)\n",
    "        y_train.append(label)\n",
    "        z_train.append(file_name)\n",
    "\n",
    "    X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "    for features,label,file_name in test_data:\n",
    "        X_test.append(features)\n",
    "        y_test.append(label)\n",
    "        z_test.append(file_name)\n",
    "\n",
    "    X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    y_test = np_utils.to_categorical(y_test,2)\n",
    "    y_train = np_utils.to_categorical(y_train,2)\n",
    "\n",
    "    X_train = X_train/255.0\n",
    "    X_test = X_test/255.0\n",
    "\n",
    "    model2.fit(X_train, y_train, batch_size=32, epochs=5, validation_split=0.3)\n",
    "    print(\"Calculating prediction\")\n",
    "    prediction2 = model2.predict(X_test, batch_size=1)\n",
    "    print(\"done\")\n",
    "    pred_index = np.argsort(prediction2)\n",
    "\n",
    "    label_pred2 = np.insert(prediction2, 2, z_test , axis =1)\n",
    "\n",
    "    print(label_pred2)\n",
    "    print(label_pred2.shape)\n",
    "\n",
    "    cat_sort2 = label_pred2[label_pred2[:,0].argsort()]\n",
    "    dog_sort2 = label_pred2[label_pred2[:,1].argsort()]\n",
    "    \n",
    "\n",
    "    ja_treinado =\"/home/reinaldo/Documentos/PetImages/ja_treinado\" \n",
    "    for img in os.listdir(TRAIN_DATADIR2+\"/Cat/\"):\n",
    "        st.move(TRAIN_DATADIR2+\"/Cat/\"+img,ja_treinado+\"/Cat/\"+img)\n",
    "    for img in os.listdir(TRAIN_DATADIR2+\"/Dog/\"):\n",
    "        st.move(TRAIN_DATADIR2+\"/Dog/\"+img,ja_treinado+\"/Dog/\"+img)\n",
    "    if len(os.listdir(TEST_DATADIR2))>100:\n",
    "        for i in range(100):\n",
    "            #path of test to training cats\n",
    "            try:\n",
    "                st.move(TEST_DATADIR2+str(int(cat_sort2[i][2]))+\".jpg\",TRAIN_DATADIR2+\"Cat/\"+str(int(cat_sort2[i][2]))+\".jpg\")\n",
    "            #path of test to training dogs\n",
    "                st.move(TEST_DATADIR2+str(int(dog_sort2[i][2]))+\".jpg\",TRAIN_DATADIR2+\"Dog/\"+str(int(dog_sort2[i][2]))+\".jpg\")\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        \n",
    "        for i in range(len(os.listdir(TEST_DATADIR2))):\n",
    "            #path of test to training cats\n",
    "            try:\n",
    "                st.move(TEST_DATADIR2+str(int(cat_sort2[i][2]))+\".jpg\",TRAIN_DATADIR2+\"Cat/\"+str(int(cat_sort2[i][2]))+\".jpg\")\n",
    "            #path of test to training dogs\n",
    "                st.move(TEST_DATADIR2+str(int(dog_sort2[i][2]))+\".jpg\",TRAIN_DATADIR2+\"Dog/\"+str(int(dog_sort2[i][2]))+\".jpg\")\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop backpropagation for Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ite=0\n",
    "while os.listdir(TEST_DATADIR3) and ite<5:\n",
    "    ite=ite+1\n",
    "    training_data = []\n",
    "    test_data = []\n",
    "    create_training_data()\n",
    "    print(\"tamanho de training data\")\n",
    "    print(len(training_data))\n",
    "    print(\"tamanho de test data\")\n",
    "    print(len(test_data))\n",
    "    random.shuffle(training_data)\n",
    "    random.shuffle(test_data)\n",
    "\n",
    "    X_test = []\n",
    "    X_train = []\n",
    "    y_test = []\n",
    "    y_train = []\n",
    "    z_train = []\n",
    "    z_test = []\n",
    "\n",
    "    for features,label,file_name in training_data:\n",
    "        X_train.append(features)\n",
    "        y_train.append(label)\n",
    "        z_train.append(file_name)\n",
    "\n",
    "    X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "    for features,label,file_name in test_data:\n",
    "        X_test.append(features)\n",
    "        y_test.append(label)\n",
    "        z_test.append(file_name)\n",
    "\n",
    "    X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    y_test = np_utils.to_categorical(y_test,2)\n",
    "    y_train = np_utils.to_categorical(y_train,2)\n",
    "\n",
    "    X_train = X_train/255.0\n",
    "    X_test = X_test/255.0\n",
    "\n",
    "    model3.fit(X_train, y_train, batch_size=32, epochs=5, validation_split=0.3)\n",
    "    print(\"Calculating prediction\")\n",
    "    prediction = model3.predict(X_test, batch_size=1)\n",
    "    print(\"done\")\n",
    "    pred_index = np.argsort(prediction3)\n",
    "\n",
    "    label_pred = np.insert(prediction3, 2, z_test , axis =1)\n",
    "\n",
    "    print(label_pred)\n",
    "    print(label_pred.shape)\n",
    "\n",
    "    cat_sort = label_pred[label_pred[:,0].argsort()]\n",
    "    dog_sort = label_pred[label_pred[:,1].argsort()]\n",
    "    \n",
    "\n",
    "    ja_treinado =\"/home/reinaldo/Documentos/PetImages/ja_treinado\" \n",
    "    for img in os.listdir(TRAIN_DATADIR3+\"/Cat/\"):\n",
    "        st.move(TRAIN_DATADIR+\"/Cat/\"+img,ja_treinado+\"/Cat/\"+img)\n",
    "    for img in os.listdir(TRAIN_DATADIR3+\"/Dog/\"):\n",
    "        st.move(TRAIN_DATADIR3+\"/Dog/\"+img,ja_treinado+\"/Dog/\"+img)\n",
    "    if len(os.listdir(TEST_DATADIR3))>100:\n",
    "        for i in range(100):\n",
    "            #path of test to training cats\n",
    "            try:\n",
    "                st.move(TEST_DATADIR3+str(int(cat_sort[i][2]))+\".jpg\",TRAIN_DATADIR3+\"Cat/\"+str(int(cat_sort[i][2]))+\".jpg\")\n",
    "            #path of test to training dogs\n",
    "                st.move(TEST_DATADIR3+str(int(dog_sort[i][2]))+\".jpg\",TRAIN_DATADIR3+\"Dog/\"+str(int(dog_sort[i][2]))+\".jpg\")\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        \n",
    "        for i in range(len(os.listdir(TEST_DATADIR3))):\n",
    "            #path of test to training cats\n",
    "            try:\n",
    "                st.move(TEST_DATADIR3+str(int(cat_sort[i][2]))+\".jpg\",TRAIN_DATADIR3+\"Cat/\"+str(int(cat_sort[i][2]))+\".jpg\")\n",
    "            #path of test to training dogs\n",
    "                st.move(TEST_DATADIR3+str(int(dog_sort[i][2]))+\".jpg\",TRAIN_DATADIR3+\"Dog/\"+str(int(dog_sort[i][2]))+\".jpg\")\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Your network is working properly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
